---
layout: post
title: Week 3
author: Gbolahan Abioye
---

6/10 - Monday

The week began with learning about LaTeX, an essential tool for formatting research papers and technical documents. The session started with basic document creation and gradually moved to advanced topics such as mathematical typesetting and bibliography management. I practiced creating various document types, which will be crucial for documenting my research findings and preparing reports. By the end of the day, I felt more confident in my ability to use LaTeX efficiently.

6/11 - Tuesday

Spent the day delving into the literature on Generative AI, focusing on techniques like Generative Adversarial Networks (GANs) and sequence-to-sequence (Seq2Seq) models for text and video generation. Reviewed several key papers on GANs, understanding how they use a discriminator and generator to create realistic data. Explored Seq2Seq models used for text and voice synthesis, noting their strengths and limitations. Discussed with peers and mentors about the advancements in Transformer models, which utilize self-attention mechanisms for handling dependencies and have largely replaced traditional Seq2Seq models. Noted how Transformers enable parallelization, significantly improving training efficiency and effectiveness for various generative tasks.

6/12 - Wednesday

Attended a research talk by a visiting scholar on the latest advancements in generative AI, which provided new insights into cutting-edge techniques and potential future directions for research in this field. Continued with the ongoing experiments related to generative models in the research labs. Conducted tests on data generated by GANs to validate their accuracy and realism. Participated in a collaborative writing session focused on drafting a research paper on generative AI methods. Shared my findings on GANs and Transformers, receiving valuable feedback from my peers. Assisted in editing sections of the paper, ensuring clarity and coherence. Resumed lab work in the afternoon, focusing on implementing a Transformer model for a text generation task and analyzing its performance compared to traditional Seq2Seq models.

6/13 - Thursday

{John Hopkins APL trip}i did not participate on the trip but i continued working on Transformer models in the research lab, refining the implementation and improving performance metrics. Discussed with my mentor the next steps for optimizing the model and potential applications. 

6/14 - Friday

Focused on finalizing the data analysis steps for the generative models looking forward to the next week.

Overall, Week 3 was intellectually stimulating and filled with productive research activities. From learning LaTeX to diving deep into generative AI methods, the experiences have been invaluable. I am looking forward to furthering my research and applying these techniques in the upcoming weeks.
[Back](./)
